import atexit
import json
import logging
import os
import signal
import sys
import threading
import time

import certifi
from bottle import run, response, Bottle, request, ServerAdapter

from bottle_plugins.error_plugin import error_plugin
from bottle_plugins.logger_plugin import logger_plugin
from bottle_plugins import prometheus_plugin
from dtos import V1RequestBase
import flaresolverr_service
import utils

env_proxy_url = os.environ.get('PROXY_URL', None)
env_proxy_username = os.environ.get('PROXY_USERNAME', None)
env_proxy_password = os.environ.get('PROXY_PASSWORD', None)


class JSONErrorBottle(Bottle):
    """
    Handle 404 errors
    """
    def default_error_handler(self, res):
        response.content_type = 'application/json'
        return json.dumps(dict(error=res.body, status_code=res.status_code))


app = JSONErrorBottle()


@app.route('/')
def index():
    """
    Show welcome message
    """
    res = flaresolverr_service.index_endpoint()
    return utils.object_to_dict(res)


@app.route('/health')
def health():
    """
    Healthcheck endpoint.
    This endpoint is special because it doesn't print traces
    """
    res = flaresolverr_service.health_endpoint()
    return utils.object_to_dict(res)


@app.post('/v1')
def controller_v1():
    """
    Controller v1
    """
    data = request.json or {}
    if (('proxy' not in data or not data.get('proxy')) and env_proxy_url is not None and (env_proxy_username is None and env_proxy_password is None)):
        logging.info('Using proxy URL ENV')
        data['proxy'] = {"url": env_proxy_url}
    if (('proxy' not in data or not data.get('proxy')) and env_proxy_url is not None and (env_proxy_username is not None or env_proxy_password is not None)):
        logging.info('Using proxy URL, username & password ENVs')
        data['proxy'] = {"url": env_proxy_url, "username": env_proxy_username, "password": env_proxy_password}
    req = V1RequestBase(data)
    res = flaresolverr_service.controller_v1_endpoint(req)
    if res.__error_500__:
        response.status = 500
    return utils.object_to_dict(res)


if __name__ == "__main__":
    # check python version
    if sys.version_info < (3, 9):
        raise Exception("The Python version is less than 3.9, a version equal to or higher is required.")

    # fix for HEADLESS=false in Windows binary
    # https://stackoverflow.com/a/27694505
    if os.name == 'nt':
        import multiprocessing
        multiprocessing.freeze_support()

    # fix ssl certificates for compiled binaries
    # https://github.com/pyinstaller/pyinstaller/issues/7229
    # https://stackoverflow.com/q/55736855
    os.environ["REQUESTS_CA_BUNDLE"] = certifi.where()
    os.environ["SSL_CERT_FILE"] = certifi.where()

    # validate configuration
    log_level = os.environ.get('LOG_LEVEL', 'info').upper()
    log_file = os.environ.get('LOG_FILE', None)
    log_html = utils.get_config_log_html()
    headless = utils.get_config_headless()
    server_host = os.environ.get('HOST', '0.0.0.0')
    server_port = int(os.environ.get('PORT', 8191))

    # configure logger
    logger_format = '%(asctime)s %(levelname)-8s %(message)s'
    if log_level == 'DEBUG':
        logger_format = '%(asctime)s %(levelname)-8s ReqId %(thread)s %(message)s'
    if log_file:
        log_file = os.path.realpath(log_file)
        log_path = os.path.dirname(log_file)
        os.makedirs(log_path, exist_ok=True)
        logging.basicConfig(
            format=logger_format,
            level=log_level,
            datefmt='%Y-%m-%d %H:%M:%S',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler(log_file)
            ]
        )
    else:
        logging.basicConfig(
            format=logger_format,
            level=log_level,
            datefmt='%Y-%m-%d %H:%M:%S',
            handlers=[
                logging.StreamHandler(sys.stdout)
            ]
        )

    # disable warning traces from urllib3
    logging.getLogger('urllib3').setLevel(logging.ERROR)
    logging.getLogger('selenium.webdriver.remote.remote_connection').setLevel(logging.WARNING)
    logging.getLogger('undetected_chromedriver').setLevel(logging.WARNING)

    logging.info(f'FlareSolverr {utils.get_flaresolverr_version()}')
    logging.debug('Debug log enabled')

    # Get current OS for global variable
    utils.get_current_platform()

    # test browser installation
    flaresolverr_service.test_browser_installation()

    # log performance optimization config
    cookie_store_path = os.environ.get('COOKIE_STORE_PATH', '/config/cookie_store.db')
    cookie_store_ttl = os.environ.get('COOKIE_STORE_TTL', '1800')
    max_concurrent = os.environ.get('MAX_CONCURRENT_BROWSERS', '1')
    queue_timeout = os.environ.get('REQUEST_QUEUE_TIMEOUT', '300')
    pool_size = os.environ.get('BROWSER_POOL_SIZE', '1')
    pool_max_req = os.environ.get('BROWSER_POOL_MAX_REQUESTS', '50')
    chrome_single = os.environ.get('CHROME_SINGLE_PROCESS', 'false')
    max_sessions = os.environ.get('MAX_SESSIONS', '10')
    session_ttl = os.environ.get('SESSION_TTL_MINUTES', '30')
    logging.info(f"Cookie store: path={cookie_store_path}, ttl={cookie_store_ttl}s")
    logging.info(f"Request queue: max_concurrent={max_concurrent}, timeout={queue_timeout}s")
    logging.info(f"Browser pool: size={pool_size}, max_requests={pool_max_req}")
    logging.info(f"Chrome: single_process={chrome_single}")
    logging.info(f"Sessions: max={max_sessions}, ttl={session_ttl}m")

    # initialize browser pool (pre-warm Chrome instances)
    flaresolverr_service.init_browser_pool()

    # start session cleanup thread
    flaresolverr_service.SESSIONS_STORAGE.start_cleanup_thread()

    # start cookie store cleanup thread
    cleanup_interval = int(os.environ.get('COOKIE_CLEANUP_INTERVAL', '3600'))

    def _cookie_cleanup_loop():
        while True:
            time.sleep(cleanup_interval)
            try:
                flaresolverr_service.COOKIE_STORE.cleanup_expired()
            except Exception as e:
                logging.debug(f"Cookie cleanup error: {e}")

    threading.Thread(target=_cookie_cleanup_loop, daemon=True, name="cookie-cleanup").start()
    logging.info(f"Cookie store cleanup thread started (interval={cleanup_interval}s)")

    # shutdown hooks â€” clean up Chrome processes on exit
    _shutdown_state = {'called': False}

    def _shutdown():
        if _shutdown_state['called']:
            return
        _shutdown_state['called'] = True
        logging.info("Shutting down...")
        flaresolverr_service.SESSIONS_STORAGE.stop()
        if flaresolverr_service.BROWSER_POOL:
            flaresolverr_service.BROWSER_POOL.shutdown()
        for sid in list(flaresolverr_service.SESSIONS_STORAGE.session_ids()):
            try:
                flaresolverr_service.SESSIONS_STORAGE.destroy(sid)
            except Exception:
                pass

    def _signal_handler(signum, frame):
        _shutdown()
        sys.exit(0)

    atexit.register(_shutdown)
    signal.signal(signal.SIGTERM, _signal_handler)
    signal.signal(signal.SIGINT, _signal_handler)

    # start bootle plugins
    # plugin order is important
    app.install(logger_plugin)
    app.install(error_plugin)
    prometheus_plugin.setup()
    app.install(prometheus_plugin.prometheus_plugin)

    # start webserver
    # default server 'wsgiref' does not support concurrent requests
    # https://github.com/FlareSolverr/FlareSolverr/issues/680
    # https://github.com/Pylons/waitress/issues/31
    class WaitressServerPoll(ServerAdapter):
        def run(self, handler):
            from waitress import serve
            serve(handler, host=self.host, port=self.port, asyncore_use_poll=True)
    run(app, host=server_host, port=server_port, quiet=True, server=WaitressServerPoll)
